Perfect 👍 Let’s do a hands-on example where we **create a Pod, expose it using a LoadBalancer Service, and test it** in AKS.

---

# 🔹 1. Create a Pod

📄 **pod.yaml**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
  labels:
    app: nginx
spec:
  containers:
  - name: nginx-container
    image: nginx:latest
    ports:
    - containerPort: 80
```

Apply it:

```bash
kubectl apply -f pod.yaml
kubectl get pods
```

✅ You should see `nginx-pod` in **Running** state.

---

# 🔹 2. Create a LoadBalancer Service

📄 **service.yaml**

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx
  type: LoadBalancer
  ports:
  - protocol: TCP
    port: 80       # Service port
    targetPort: 80 # Pod port
```

Apply it:

```bash
kubectl apply -f service.yaml
kubectl get svc
```

* Look at the **EXTERNAL-IP** column.
* It may take **1–2 minutes** for Azure to provision a public IP.

---

# 🔹 3. Test the Application

1. Copy the **EXTERNAL-IP** from `kubectl get svc nginx-service`.
2. Open in a browser:

```
http://<EXTERNAL-IP>
```

✅ You should see the **Nginx welcome page**.

---

# 🔹 4. Cleanup After Testing

```bash
kubectl delete svc nginx-service
kubectl delete pod nginx-pod
```

---

# 🔹 Summary

* Created a **Pod** (`nginx-pod`).
* Exposed it using **LoadBalancer Service** (`nginx-service`).
* Tested externally using Azure’s public IP.
* Pods are ephemeral, but the LoadBalancer provides a stable **external endpoint**.

---

👉 Shyam, do you want me to **upgrade this example using a Deployment instead of a single Pod** so it’s production-ready with **auto-scaling** and **self-healing**?
