Perfect ğŸ‘ Letâ€™s do a hands-on example where we **create a Pod, expose it using a LoadBalancer Service, and test it** in AKS.

---

# ğŸ”¹ 1. Create a Pod

ğŸ“„ **pod.yaml**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
  labels:
    app: nginx
spec:
  containers:
  - name: nginx-container
    image: nginx:latest
    ports:
    - containerPort: 80
```

Apply it:

```bash
kubectl apply -f pod.yaml
kubectl get pods
```

âœ… You should see `nginx-pod` in **Running** state.

---

# ğŸ”¹ 2. Create a LoadBalancer Service

ğŸ“„ **service.yaml**

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx
  type: LoadBalancer
  ports:
  - protocol: TCP
    port: 80       # Service port
    targetPort: 80 # Pod port
```

Apply it:

```bash
kubectl apply -f service.yaml
kubectl get svc
```

* Look at the **EXTERNAL-IP** column.
* It may take **1â€“2 minutes** for Azure to provision a public IP.

---

# ğŸ”¹ 3. Test the Application

1. Copy the **EXTERNAL-IP** from `kubectl get svc nginx-service`.
2. Open in a browser:

```
http://<EXTERNAL-IP>
```

âœ… You should see the **Nginx welcome page**.

---

# ğŸ”¹ 4. Cleanup After Testing

```bash
kubectl delete svc nginx-service
kubectl delete pod nginx-pod
```

---

# ğŸ”¹ Summary

* Created a **Pod** (`nginx-pod`).
* Exposed it using **LoadBalancer Service** (`nginx-service`).
* Tested externally using Azureâ€™s public IP.
* Pods are ephemeral, but the LoadBalancer provides a stable **external endpoint**.

---

ğŸ‘‰ Shyam, do you want me to **upgrade this example using a Deployment instead of a single Pod** so itâ€™s production-ready with **auto-scaling** and **self-healing**?
